# Select provider: ollama, openai, or gemini
LLM_PROVIDER=ollama
LLM_MODEL=llama3.2

# Ollama configuration (if using ollama)
OLLAMA_BASE_URL=http://localhost:11434

# OpenAI configuration (if using openai)
# OPENAI_API_KEY=sk-xxx
# OPENAI_BASE_URL=https://api.openai.com  # Optional, for Azure OpenAI

# Gemini configuration (if using gemini)
# GEMINI_API_KEY=xxx

# For Vertex AI (instead of API key)
# GEMINI_PROJECT_ID=my-project
# GEMINI_LOCATION=us-central1

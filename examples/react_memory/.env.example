# LLM Provider Configuration
LLM_PROVIDER=ollama
LLM_MODEL=qwen3:1.7b

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434

# Vector Memory (set to true to enable Qdrant)
USE_VECTOR_MEMORY=false

# Qdrant Configuration (only needed if USE_VECTOR_MEMORY=true)
QDRANT_URL=localhost:6334
QDRANT_COLLECTION=react_agent_demo

# Embedding Model (for Vector Memory)
EMBEDDING_MODEL=nomic-embed-text

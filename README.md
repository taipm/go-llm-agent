# ğŸ¤– go-llm-agent

[![Go Version](https://img.shields.io/badge/Go-1.21+-00ADD8?style=flat&logo=go)](https://go.dev/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Status](https://img.shields.io/badge/status-alpha-orange.svg)](ROADMAP.md)

**go-llm-agent** lÃ  thÆ° viá»‡n Go Ä‘Æ¡n giáº£n, máº¡nh máº½ Ä‘á»ƒ xÃ¢y dá»±ng AI agents thÃ´ng minh vá»›i kháº£ nÄƒng sá»­ dá»¥ng tools vÃ  duy trÃ¬ context. Báº¯t Ä‘áº§u vá»›i Ollama support, tiáº¿n hÃ³a dáº§n Ä‘á»ƒ support nhiá»u LLM providers.

## âœ¨ TÃ­nh nÄƒng chÃ­nh

- ğŸš€ **Simple & Intuitive API** - Dá»… há»c, dá»… dÃ¹ng trong vÃ i phÃºt
- ğŸ”§ **Tool System** - Cho phÃ©p agent thá»±c hiá»‡n cÃ¡c tÃ¡c vá»¥ thá»±c táº¿
- ğŸ’¬ **Conversation Memory** - Duy trÃ¬ context qua nhiá»u lÆ°á»£t há»™i thoáº¡i
- ğŸ“¡ **Streaming Responses** - Real-time output cho UX tá»‘t hÆ¡n
- ğŸ¦™ **Ollama First** - Cháº¡y local models miá»…n phÃ­ vá»›i Ollama
- ğŸ“¦ **Zero Dependencies** - Chá»‰ dÃ¹ng Go standard library
- ğŸ§ª **Production Ready** - Test coverage cao, error handling tá»‘t

## ğŸ¯ Use Cases

- **Chatbots thÃ´ng minh** vá»›i kháº£ nÄƒng truy cáº­p dá»¯ liá»‡u thá»±c
- **CLI assistants** tá»± Ä‘á»™ng hÃ³a workflows
- **Data analysis agents** xá»­ lÃ½ vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u
- **Code assistants** há»— trá»£ development tasks
- **Customer service bots** vá»›i domain knowledge

## ğŸ“¦ Installation

```bash
go get github.com/taipm/go-llm-agent
```

**Prerequisites:**
- Go 1.21 trá»Ÿ lÃªn
- [Ollama](https://ollama.ai/) Ä‘Ã£ cÃ i Ä‘áº·t vÃ  Ä‘ang cháº¡y

```bash
# CÃ i Ä‘áº·t Ollama (náº¿u chÆ°a cÃ³)
curl -fsSL https://ollama.ai/install.sh | sh

# Pull model
ollama pull llama3.2
```

## ğŸš€ Quick Start

### 1. Simple Chat

```go
package main

import (
    "context"
    "fmt"
    "log"
    
    "github.com/taipm/go-llm-agent/agent"
    "github.com/taipm/go-llm-agent/provider/ollama"
)

func main() {
    ctx := context.Background()
    
    // Táº¡o Ollama provider
    provider := ollama.New("http://localhost:11434", "llama3.2")
    
    // Táº¡o agent
    agent := agent.New(provider)
    
    // Chat
    response, err := agent.Chat(ctx, "What is the capital of France?")
    if err != nil {
        log.Fatal(err)
    }
    
    fmt.Println(response)
    // Output: The capital of France is Paris.
}
```

### 2. Agent with Tools

```go
package main

import (
    "context"
    "fmt"
    "log"
    "time"
    
    "github.com/taipm/go-llm-agent/agent"
    "github.com/taipm/go-llm-agent/provider/ollama"
    "github.com/taipm/go-llm-agent/tool"
)

// Äá»‹nh nghÄ©a má»™t tool Ä‘Æ¡n giáº£n
type WeatherTool struct{}

func (w *WeatherTool) Name() string {
    return "get_weather"
}

func (w *WeatherTool) Description() string {
    return "Get current weather for a location"
}

func (w *WeatherTool) Parameters() *tool.JSONSchema {
    return &tool.JSONSchema{
        Type: "object",
        Properties: map[string]*tool.JSONSchema{
            "location": {
                Type:        "string",
                Description: "City name",
            },
        },
        Required: []string{"location"},
    }
}

func (w *WeatherTool) Execute(ctx context.Context, params map[string]interface{}) (interface{}, error) {
    location := params["location"].(string)
    
    // Mock weather data
    return map[string]interface{}{
        "location":    location,
        "temperature": 22,
        "condition":   "Sunny",
        "timestamp":   time.Now().Format(time.RFC3339),
    }, nil
}

func main() {
    ctx := context.Background()
    
    // Setup agent vá»›i tool
    provider := ollama.New("http://localhost:11434", "llama3.2")
    agent := agent.New(provider)
    
    // ÄÄƒng kÃ½ tool
    weatherTool := &WeatherTool{}
    agent.AddTool(weatherTool)
    
    // Agent sáº½ tá»± Ä‘á»™ng gá»i tool khi cáº§n
    response, err := agent.Chat(ctx, "What's the weather like in Tokyo?")
    if err != nil {
        log.Fatal(err)
    }
    
    fmt.Println(response)
    // Output: Based on current data, it's sunny in Tokyo with temperature of 22Â°C.
}
```

### 3. Streaming Responses (New!)

```go
package main

import (
    "context"
    "fmt"
    "log"
    
    "github.com/taipm/go-llm-agent/agent"
    "github.com/taipm/go-llm-agent/provider/ollama"
    "github.com/taipm/go-llm-agent/types"
)

func main() {
    ctx := context.Background()
    
    provider := ollama.New("http://localhost:11434", "llama3.2")
    agent := agent.New(provider)
    
    // Stream response in real-time
    handler := func(chunk types.StreamChunk) error {
        if chunk.Content != "" {
            fmt.Print(chunk.Content) // Print as tokens arrive
        }
        if chunk.Done {
            fmt.Println("\nâœ“ Done")
        }
        return nil
    }
    
    err := agent.ChatStream(ctx, "Tell me a short story", handler)
    if err != nil {
        log.Fatal(err)
    }
}
```

### 4. Multi-turn Conversation

```go
package main

import (
    "context"
    "fmt"
    "log"
    
    "github.com/taipm/go-llm-agent/agent"
    "github.com/taipm/go-llm-agent/memory"
    "github.com/taipm/go-llm-agent/provider/ollama"
)

func main() {
    ctx := context.Background()
    
    // Táº¡o agent vá»›i memory
    provider := ollama.New("http://localhost:11434", "llama3.2")
    mem := memory.NewBuffer(100) // LÆ°u 100 messages
    
    agent := agent.New(provider, agent.WithMemory(mem))
    
    // Conversation
    resp1, _ := agent.Chat(ctx, "My name is John and I love programming")
    fmt.Println(resp1)
    
    resp2, _ := agent.Chat(ctx, "What's my name?")
    fmt.Println(resp2)
    // Output: Your name is John.
    
    resp3, _ := agent.Chat(ctx, "What do I love?")
    fmt.Println(resp3)
    // Output: You love programming.
}
```

## ğŸ“– Documentation

- [ğŸ“‹ SPEC.md](SPEC.md) - Äáº·c táº£ ká»¹ thuáº­t chi tiáº¿t
- [ğŸ—ºï¸ ROADMAP.md](ROADMAP.md) - Káº¿ hoáº¡ch phÃ¡t triá»ƒn
- [ğŸ“š Examples](examples/) - Code examples Ä‘áº§y Ä‘á»§
- [ğŸ”§ API Reference](https://pkg.go.dev/github.com/taipm/go-llm-agent) - Go package docs

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Your Application                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Agent                          â”‚
â”‚  - Chat(), Run(), Execute()                 â”‚
â”‚  - Orchestrates LLM, Tools, Memory          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         â”‚         â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM   â”‚ â”‚ Tools  â”‚ â”‚ Memory  â”‚
â”‚Providerâ”‚ â”‚ System â”‚ â”‚ Manager â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

1. **Agent** - Trung tÃ¢m Ä‘iá»u phá»‘i, quáº£n lÃ½ workflow
2. **LLM Provider** - Interface vá»›i cÃ¡c LLM (Ollama, OpenAI, v.v.)
3. **Tool System** - Cho phÃ©p agent thá»±c hiá»‡n actions
4. **Memory** - LÆ°u trá»¯ vÃ  quáº£n lÃ½ conversation context

## ğŸ›£ï¸ Roadmap

### âœ… v0.1 - Foundation (Current)

- Basic agent vá»›i Ollama
- Simple tool system
- In-memory conversation history
- Working examples
- **Streaming responses** âœ¨ (New)

### ğŸ”„ v0.2 - Enhanced (Next)

- 10+ built-in tools
- Advanced configuration
- Performance optimizations
- Better error handling

### ğŸ”® v0.3 - Multi-Provider

- OpenAI/Azure OpenAI support
- Anthropic Claude support
- Persistent storage
- Production features

[Chi tiáº¿t Ä‘áº§y Ä‘á»§ táº¡i ROADMAP.md](ROADMAP.md)

## ğŸ¤ Contributing

Dá»± Ã¡n Ä‘ang trong giai Ä‘oáº¡n Ä‘áº§u phÃ¡t triá»ƒn. Má»i Ä‘Ã³ng gÃ³p Ä‘á»u Ä‘Æ°á»£c hoan nghÃªnh!

```bash
# Clone repository
git clone https://github.com/taipm/go-llm-agent.git
cd go-llm-agent

# Run tests
go test ./...

# Run examples
go run examples/simple_chat/main.go
```

## ğŸ“ License

MIT License - xem [LICENSE](LICENSE) Ä‘á»ƒ biáº¿t chi tiáº¿t.

## ğŸ™ Acknowledgments

- [Ollama](https://ollama.ai/) - Local LLM runtime tuyá»‡t vá»i
- [LangChain](https://github.com/langchain-ai/langchain) - Inspiration cho architecture
- Go Community - VÃ¬ má»™t ngÃ´n ngá»¯ tuyá»‡t vá»i

## ğŸ“§ Contact

- Author: taipm
- GitHub: [@taipm](https://github.com/taipm)
- Issues: [GitHub Issues](https://github.com/taipm/go-llm-agent/issues)

---

**âš ï¸ Status**: Alpha - API cÃ³ thá»ƒ thay Ä‘á»•i. KhÃ´ng khuyáº¿n khÃ­ch dÃ¹ng trong production.

**ğŸŒŸ Star this repo** náº¿u báº¡n tháº¥y project há»¯u Ã­ch!
